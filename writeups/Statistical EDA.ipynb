{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "data = pd.read_csv('full_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has variance in review scores been decreasing over time? By breaking the data into two groups for older music and more recent music, we can run a t-test on the standard deviations of each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T score: 4.81, P value: 0.00031\n"
     ]
    }
   ],
   "source": [
    "annual_stds = data.groupby('publication_year').std().score\n",
    "older_music = annual_stds[annual_stds.index <= 2007]\n",
    "recent_music = annual_stds[annual_stds.index > 2007]\n",
    "T, p = scipy.stats.ttest_ind(older_music, recent_music, equal_var = False)\n",
    "print(\"T score: {:.2f}, P value: {:.5f}\".format(T, p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results indicate that yes, variance in reviews has been shrinking over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, there did not appear to be relationships between the audio feature variables and review score. The variable used as an example was liveliness. Taking a mathematical approach instead of a visual one, we can calculate the Pearson's correlation coefficient between liveliness and review score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>liveness_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness_mean</th>\n",
       "      <td>-0.002919</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score  liveness_mean\n",
       "score          1.000000      -0.002919\n",
       "liveness_mean -0.002919       1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['score', 'liveness_mean']].corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of -0.0029 confirms our suspicion that there is no relationship between these two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have albums been getting louder and more energetic over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T score: -7.45, P value: 0.0000\n",
      "T score: 8.65, P value: 0.0000\n",
      "T score: -7.21, P value: 0.0000\n",
      "T score: 10.81, P value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "older_music = data[data.release_year <= 2006].dropna()\n",
    "recent_music = data[data.release_year > 2006].dropna()\n",
    "\n",
    "energy_mean_T, energy_mean_P = scipy.stats.ttest_ind(older_music.energy_mean, recent_music.energy_mean, equal_var=False)\n",
    "print(\"T score: {:.2f}, P value: {:.4f}\".format(energy_mean_T, energy_mean_P))\n",
    "energy_std_T, energy_std_P = scipy.stats.ttest_ind(older_music.energy_std, recent_music.energy_std, equal_var=False)\n",
    "print(\"T score: {:.2f}, P value: {:.4f}\".format(energy_std_T, energy_std_P))\n",
    "\n",
    "loudness_mean_T, loudness_mean_P = scipy.stats.ttest_ind(older_music.loudness_mean, recent_music.loudness_mean, equal_var=False)\n",
    "print(\"T score: {:.2f}, P value: {:.4f}\".format(loudness_mean_T, loudness_mean_P))\n",
    "\n",
    "loudness_std_T, loudness_std_P = scipy.stats.ttest_ind(older_music.loudness_std, recent_music.loudness_std, equal_var=False)\n",
    "print(\"T score: {:.2f}, P value: {:.4f}\".format(loudness_std_T, loudness_std_P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very large T-scores and correspondingly small P-values indicate that the trends we observed are undeniable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score: 2.58, P value: 0.0028\n"
     ]
    }
   ],
   "source": [
    "keys = pd.unique(data.primary_key)\n",
    "key_data = {key:data['score'][data.primary_key == key] for key in keys}\n",
    "F, p = scipy.stats.f_oneway(key_data['F#/Gb'], key_data['G'], key_data['C'], key_data['D'], key_data['A'], key_data['C#/Db'], key_data['A#/Bb'], key_data['B'], key_data['E'], key_data['F'], key_data['G#/A'], key_data['D#/Eb'])\n",
    "print(\"F score: {:.2f}, P value: {:.4f}\".format(F, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scores are testing the null hypothesis that the mean of every single group (in this case, key) is identical. From our visualization, it appeared as though the less common keys behaved differently from the more common keys. If we remove the less common keys (those with under 1000 albums) from the F test, our results change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score: 1.08, P value: 0.3666\n",
      "F score: 2.81, P value: 0.0156\n"
     ]
    }
   ],
   "source": [
    "F, p = scipy.stats.f_oneway(key_data['G'], key_data['C'], key_data['D'], key_data['A'], key_data['C#/Db'], key_data['B'])\n",
    "print(\"F score: {:.2f}, P value: {:.4f}\".format(F, p))\n",
    "\n",
    "F, p = scipy.stats.f_oneway(key_data['F#/Gb'], key_data['A#/Bb'],  key_data['E'], key_data['F'], key_data['G#/A'], key_data['D#/Eb'])\n",
    "print(\"F score: {:.2f}, P value: {:.4f}\".format(F, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that among the popular keys, there is no difference between keys - however, in the less common keys, differences do exist. Are the two groups (common and uncommon keys) different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common key average score: 6.92\n",
      "Uncommon key average score: 7.01\n",
      "T score: -3.15, P value: 0.0016\n"
     ]
    }
   ],
   "source": [
    "key_groups = data.groupby('primary_key').count().score\n",
    "common_keys = key_groups[key_groups >= 1000]\n",
    "uncommon_keys = key_groups[key_groups < 1000]\n",
    "\n",
    "#data.loc[data.primary_key in common_keys]\n",
    "common_key_data = data.loc[data.primary_key.isin(common_keys.index)]\n",
    "uncommon_key_data = data.loc[data.primary_key.isin(uncommon_keys.index)]\n",
    "\n",
    "T, p = scipy.stats.ttest_ind(common_key_data.score, uncommon_key_data.score)\n",
    "print(\"Common key average score: {:.2f}\".format(common_key_data.score.mean()))\n",
    "print(\"Uncommon key average score: {:.2f}\".format(uncommon_key_data.score.mean()))\n",
    "print(\"T score: {:.2f}, P value: {:.4f}\".format(T, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a p-value of .001, we can reject the null hypothesis that albums written primarily in common keys and albums written primarily in uncommon keys receive the same scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our visualization of album quality by genre, we would like to assign a numeric value to how much each individual genre impacts album score. Once again, F testing allows for comparisons of each genre of music, seeing if certain genres have an impact on quality category. The results of these tests can be interpreted as testing the null hypothesis that the genre does not impact if an album is top 10%, bottom 10%, or in the middle, versus the alternative hypothesis that genre does have an impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pefect 10s: 15\n",
      "Number of albums at or below 5.3 - 1292\n",
      "Number of albums at or above 8.2 - 1488\n",
      "Number of albums between the two cutoffs - 9830\n"
     ]
    }
   ],
   "source": [
    "masterpieces = data.loc[data.score==10]\n",
    "print(\"Number of pefect 10s:\", masterpieces.shape[0])\n",
    "\n",
    "lower_quantile = data.score.quantile(.1)\n",
    "flops = data.loc[data.score <= lower_quantile]\n",
    "print(\"Number of albums at or below\", lower_quantile, \"-\", flops.shape[0])\n",
    "\n",
    "upper_quantile = data.score.quantile(.9)\n",
    "classics = data.loc[data.score >= upper_quantile]\n",
    "print(\"Number of albums at or above\", upper_quantile, '-', classics.shape[0])\n",
    "\n",
    "regular_albums = data.loc[(data.score > lower_quantile) & (data.score <= upper_quantile)]\n",
    "print(\"Number of albums between the two cutoffs -\", regular_albums.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental: F score: 39.04, P value: 0.0000\n",
      "Rock: F score: 20.31, P value: 0.0000\n",
      "Pop/R&B: F score: 6.63, P value: 0.0013\n",
      "Folk/Country: F score: 5.83, P value: 0.0029\n",
      "Electronic: F score: 5.01, P value: 0.0067\n",
      "Rap: F score: 3.87, P value: 0.0209\n",
      "Jazz: F score: 3.57, P value: 0.0281\n",
      "Metal: F score: 0.96, P value: 0.3833\n"
     ]
    }
   ],
   "source": [
    "F, p = scipy.stats.f_oneway(flops['experimental'], classics['experimental'], regular_albums['experimental'])\n",
    "print(\"Experimental: F score: {:.2f}, P value: {:.4f}\".format(F, p))\n",
    "\n",
    "F, p = scipy.stats.f_oneway(flops['rock'], classics['rock'], regular_albums['rock'])\n",
    "print(\"Rock: F score: {:.2f}, P value: {:.4f}\".format(F, p))\n",
    "\n",
    "F, p = scipy.stats.f_oneway(flops['pop/r&b'], classics['pop/r&b'], regular_albums['pop/r&b'])\n",
    "print(\"Pop/R&B: F score: {:.2f}, P value: {:.4f}\".format(F, p))\n",
    "\n",
    "F, p = scipy.stats.f_oneway(flops['folk/country'], classics['folk/country'], regular_albums['folk/country'])\n",
    "print(\"Folk/Country: F score: {:.2f}, P value: {:.4f}\".format(F, p))\n",
    "\n",
    "F, p = scipy.stats.f_oneway(flops['electronic'], classics['electronic'], regular_albums['electronic'])\n",
    "print(\"Electronic: F score: {:.2f}, P value: {:.4f}\".format(F, p))\n",
    "\n",
    "F, p = scipy.stats.f_oneway(flops['rap'], classics['rap'], regular_albums['rap'])\n",
    "print(\"Rap: F score: {:.2f}, P value: {:.4f}\".format(F, p))\n",
    "\n",
    "F, p = scipy.stats.f_oneway(flops['jazz'], classics['jazz'], regular_albums['jazz'])\n",
    "print(\"Jazz: F score: {:.2f}, P value: {:.4f}\".format(F, p))\n",
    "\n",
    "F, p = scipy.stats.f_oneway(flops['metal'], classics['metal'], regular_albums['metal'])\n",
    "print(\"Metal: F score: {:.2f}, P value: {:.4f}\".format(F, p))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results indicate that some genres have a very considerable impact on quality, while others have a smaller but still significant impact, and that for one genre (metal), there is no impact. This confirms what we saw in the visualization - not all genres are rated equally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
